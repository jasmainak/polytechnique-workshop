{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:green;\">scikit-learn</span></h2>\n",
    "\n",
    "scikit-learn is an advanced machine-learning package. We will explore classification, cross validation and grid search.\n",
    "\n",
    "## Classification\n",
    "\n",
    "In this section, we will use an SVM on the [MNIST digits dataset](http://yann.lecun.com/exdb/mnist/) to train a classifier to predict the labels of the last sample. \n",
    "\n",
    "All the sample datasets in scikit-learn can be found in the `datasets` module. Let us inspect the digits dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "[[  0.   0.   5. ...,   0.   0.   0.]\n",
      " [  0.   0.   0. ...,  10.   0.   0.]\n",
      " [  0.   0.   0. ...,  16.   9.   0.]\n",
      " ..., \n",
      " [  0.   0.   1. ...,   6.   0.   0.]\n",
      " [  0.   0.   2. ...,  12.   0.   0.]\n",
      " [  0.   0.  10. ...,  12.   1.   0.]]\n",
      "Target\n",
      "[0 1 2 ..., 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "print('Data')\n",
    "print(digits.data)\n",
    "\n",
    "print('Target')\n",
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, the feature vector is always in the form of (n_samples, n_features). It is already conveniently reshaped for us. However, if we would like to use the original images, we can always reshape it like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = digits.images.reshape((digits.images.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we can take a look at the reshaped data (compared to scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn: n_samples = 1797, n_features = 64\n",
      "myfeatures: n_samples = 1797, n_features = 64\n"
     ]
    }
   ],
   "source": [
    "print('scikit-learn: n_samples = %d, n_features = %d' % (digits.data.shape[0], digits.data.shape[1]))\n",
    "print('myfeatures: n_samples = %d, n_features = %d' % (data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main object in scikit-learn is an `estimator`. An `estimator` implements three important methods: `fit`, `transform` and `predict`. The `fit` method is used to estimate the parameters of a model. The `transform` method transforms the data. This is often used for feature extraction or feature selection. The `predict` method predicts the labels.\n",
    "\n",
    "First, let us instantiate an estimator object. We will use a Support Vector Machine (SVM) with Radial Basis Function (RBF) kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can train the SVM using all but the last sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(digits.data[:-1], digits.target[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can ask our SVM classifier to predict the label of the last sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because most scikit-learn objects follow a similar API, it is very easy to try other classifiers by simply changing `clf = svm.SVC(gamma=0.001, C=100.)` to any other classifier.\n",
    "\n",
    "** Q1 ** _Can you use_ [Linear Discriminant Analysis](http://scikit-learn.org/stable/modules/lda_qda.html#lda-qda) _instead of SVC for the prediction?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "To avoid dataset biases, we must train and test on different subsets of the data to check model performance.\n",
    "\n",
    "First, let us instantiate an iterator for cross validation. scikit-learn provides a bunch of iterators for cross validation: `KFold`, `StratifiedKFold`, `LeaveOneOut` etc.  Here is a [complete list](http://scikit-learn.org/stable/modules/cross_validation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "# ShuffleSplit?\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can either iterate over the splits using a simple for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, accuracy =  0.99\n",
      "Fold 2, accuracy =  0.99\n",
      "Fold 3, accuracy =  0.99\n",
      "Fold 4, accuracy =  0.99\n",
      "Fold 5, accuracy =  0.98\n"
     ]
    }
   ],
   "source": [
    "for ii, (train, test) in enumerate(cv.split(digits.data)):\n",
    "\n",
    "    clf.fit(digits.data[train], digits.target[train])\n",
    "    pred_labels = clf.predict(digits.data[test])\n",
    "    score = clf.score(digits.data[test], digits.target[test])\n",
    "    \n",
    "    print('Fold %d, accuracy =  %0.2f' % (ii + 1, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do all this in one line using the `cross_val_score` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.98888889,  0.99166667,  0.98888889,  0.99444444,  0.98333333])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# cross_val_score?\n",
    "cross_val_score(clf, X=digits.data, y=digits.target, cv=cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
